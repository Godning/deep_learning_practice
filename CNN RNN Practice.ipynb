{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some exercise for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from tensorflow.contrib import rnn\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model_fn(features, labels, mode, params = None): #params will be used for hyper params\n",
    "    \n",
    "    num_time_steps = 12;\n",
    "    num_dims = 1;\n",
    "    num_hidden_units = 24;\n",
    "    num_outputs = 13;\n",
    "    \n",
    "    input_layer = tf.unstack(features['x'], num_time_steps, num_dims)# (data, time_steps, 1), cut into 10 pieces\n",
    "    \n",
    "    lstm_layer = rnn.BasicLSTMCell(num_hidden_units )\n",
    "    \n",
    "    outputs, _ = rnn.static_rnn(lstm_layer, input_layer ,dtype = \"float32\")\n",
    "    \n",
    "    logits = tf.layers.dense(inputs = outputs[-1], units = num_outputs)\n",
    "    \n",
    "    Final_EstimatorSpec = GenerateEstimatorSpec(logits, labels, mode)\n",
    "    return(Final_EstimatorSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode, params = None): #params will be used for hyper params\n",
    "    \n",
    "    # features: This is the first item returned from the input_fn passed to train\n",
    "    # labels: This is the second item returned from the input_fn passed to train\n",
    "    \n",
    "    #input layer (reshape from 784 cells)\n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1]) \n",
    "    #[batch_size, image_width, image_height, channels], -1: dynamic compute\n",
    "    \n",
    "    # Convolutonal Layer 1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs = input_layer,\n",
    "        filters = 32, #number of filters\n",
    "        kernel_size = [5,5], #filter size, or kernel_size = 5\n",
    "        strides=(1, 1), #move along 2 dirs\n",
    "        padding = \"same\", # other options: \"valid\"\n",
    "        activation = tf.nn.relu,\n",
    "        name = \"CL_1\"\n",
    "        )\n",
    "    \n",
    "    # Note the output dimension: 28 * 28 * 32\n",
    "    \n",
    "    # Pooling Layer 1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs = conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)\n",
    "    \n",
    "    # Note the output dimension: 14 * 14 * 32\n",
    "    \n",
    "    # Convolutonal Layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs = pool1,\n",
    "        filters = 64, #number of filters\n",
    "        kernel_size = [5,5], #filter size\n",
    "        padding = \"same\", # other options: \"valid\"\n",
    "        activation = tf.nn.relu,\n",
    "        name = \"CL_2\"\n",
    "    )\n",
    "    \n",
    "    # Note the output dimension: 14 * 14 * 64\n",
    "    \n",
    "    # Pooling Layer 2\n",
    "    pool2 = tf.layers.max_pooling2d(inputs = conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2)\n",
    "    \n",
    "    # Note the output dimension: 7 * 7 * 64\n",
    "    \n",
    "    # Flatten layer (same below??)\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64]) # 3136 weights\n",
    "    pool2_flat = tf.layers.flatten(pool2)\n",
    "    \n",
    "    # FC layer (dense layer)\n",
    "    dense = tf.layers.dense(inputs = pool2_flat, \n",
    "                            units=1024, # 3136 --> 1024\n",
    "                            activation = tf.nn.relu)\n",
    "    \n",
    "    # Drop-out layer\n",
    "    dropout = tf.layers.dropout(inputs=dense, \n",
    "                                rate=0.4, \n",
    "                    training = mode == tf.estimator.ModeKeys.TRAIN)# only activate during training\n",
    "    \n",
    "    # Final layer (10 logits)\n",
    "    logits = tf.layers.dense(inputs = dropout, units = 10)\n",
    "    \n",
    "\n",
    "\n",
    "    Final_EstimatorSpec = GenerateEstimatorSpec(logits, labels, mode)\n",
    "    return(Final_EstimatorSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GenerateEstimatorSpec(logits, labels, mode):\n",
    "    # Generate Predictions\n",
    "    predictions = {\n",
    "      \"classes\": tf.argmax(input = logits, axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    # If during training mode, just return the predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, \n",
    "                                          predictions = predictions)\n",
    "    \n",
    "    # If during Train or Eval, calculate cross-entropy loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels, \n",
    "                                                  logits = logits)\n",
    "\n",
    "    # If during Train, update gradients\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss = loss,\n",
    "            global_step = tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode = mode, \n",
    "                                          loss = loss, \n",
    "                                          train_op = train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "              labels = labels, \n",
    "              predictions = predictions[\"classes\"])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode = mode, loss = loss, eval_metric_ops = eval_metric_ops) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Use CNN to train MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "train_data = mnist.train.images # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "eval_data = mnist.test.images # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns model input\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data}, # features \n",
    "    y=train_labels, # targets\n",
    "    batch_size = 100, \n",
    "    num_epochs = None, # forever, the model will train until the specified number of steps is reached\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model_files', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1818522ac8>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function cnn_model_fn at 0x1089311e0>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn = cnn_model_fn, # model function type, \n",
    "    model_dir = \"./model_files\",\n",
    "    params = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logging_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier.train(\n",
    "    input_fn = train_input_fn,\n",
    "    steps = 5000)\n",
    "    #hooks = [logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-04-27-18:15:00\n",
      "INFO:tensorflow:Restoring parameters from ./model_files/model.ckpt-1\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-27-18:15:06\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.1369, global_step = 1, loss = 2.29783\n",
      "{'accuracy': 0.13689999, 'loss': 2.2978327, 'global_step': 1}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data}, #features \n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use RNN(LSTM) to train \"sum\" operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = ['{0:012b}'.format(i) for i in range(2**12)] \n",
    "shuffle(train_input)\n",
    "ti  = []\n",
    "for i in train_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "        temp_list.append([j])\n",
    "    ti.append(temp_list)\n",
    "\n",
    "train_input = np.array(ti, dtype=np.float32)\n",
    "train_input[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output = []\n",
    "for i in train_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    train_output.append(count)\n",
    "\n",
    "train_output = np.array(train_output, dtype=np.int32)\n",
    "train_output[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 4000\n",
    "train_data = train_input[:NUM_EXAMPLES]\n",
    "train_labels = train_output[:NUM_EXAMPLES]\n",
    "eval_data = train_input[NUM_EXAMPLES:]\n",
    "eval_labels = train_output[NUM_EXAMPLES:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns model input\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data}, # features \n",
    "    y=train_labels, # targets\n",
    "    batch_size = 5, \n",
    "    num_epochs = None, # forever, the model will train until the specified number of steps is reached\n",
    "    shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model_files_2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1c1d85b710>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function rnn_model_fn at 0x1c1ae7c400>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "sum_classifier = tf.estimator.Estimator(\n",
    "    model_fn = rnn_model_fn, # model function type, \n",
    "    model_dir = \"./model_files_2\",\n",
    "    params = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_classifier.train(\n",
    "    input_fn = train_input_fn,\n",
    "    steps = 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-04-27-18:18:42\n",
      "INFO:tensorflow:Restoring parameters from ./model_files_2/model.ckpt-60000\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-27-18:18:42\n",
      "INFO:tensorflow:Saving dict for global step 60000: accuracy = 0.854167, global_step = 60000, loss = 0.646825\n",
      "{'accuracy': 0.85416669, 'loss': 0.6468249, 'global_step': 60000}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and print results\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": eval_data}, #features \n",
    "    y = eval_labels,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "\n",
    "eval_results = sum_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the model and print results\n",
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data}, #features \n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = sum_classifier.predict(input_fn=pred_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_files_2/model.ckpt-60000\n",
      "{'classes': 6, 'probabilities': array([  9.85412553e-05,   1.15618590e-04,   9.50663642e-04,\n",
      "         1.18006172e-03,   8.71421304e-03,   1.33088320e-01,\n",
      "         7.54086554e-01,   9.57260802e-02,   4.28593345e-03,\n",
      "         6.86499756e-04,   5.44067007e-04,   4.79791430e-04,\n",
      "         4.38047573e-05], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "for i in pred_results:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
