{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some key concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Background**\n",
    "- feature engineering and SVM\n",
    "- conputational speed and GPU\n",
    "- dataset size and internet, orders of magnitude more data\n",
    "- Framework such as TF, Keras\n",
    "\n",
    "**NN as universal approximators**\n",
    "- More neurons --> more complicated functions\n",
    "- Regularization to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Activation Function**\n",
    "- Sigmoid\n",
    "    * Saturated at 0/1 and kills gradients (derivative -> 0)\n",
    "    * Output not zero-centred; for next layer: f = wx + b, x>0, df/dw same sign for all w; zig-zag update trajectory\n",
    "- Tanh\n",
    "    * Still kills gradients\n",
    "    * But: zero-cented\n",
    "- ReLU\n",
    "    * Non-saturated, linearity --> Accelerate convergence\n",
    "    * Cheap computation\n",
    "    * But: Can die; never activate\n",
    "    * Extension: Leaky ReLU, maxout\n",
    "    \n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*feheZP3rz5va0QVpi9DVNg.png\", width=800>\n",
    "\n",
    "\n",
    "## **Regularization**\n",
    "- L1/L2/ElasticNet\n",
    "- Max Norm constraint\n",
    "- Drop Out layer\n",
    "\n",
    "## **Hyperparameter Optimization**\n",
    "- Single validation set > cross validation in practice\n",
    "- Random search instead of grid search within a range\n",
    "- Metric selection: accuracy, RMSE, etc.\n",
    "- Ideally: Training + Validation + Test, where validation set is to *\"learn\"* hyperparameters. \n",
    "    - Think of hyperparam tuning itself a learning algorithm and validation set becomes \"training set\" in the new problem.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Weights Initialization**\n",
    "- **All zero**: \n",
    "    - Wrong: neuron outputs and gradients would be same; same update\n",
    "    - We don't want the symmetric structure of weights\n",
    "    \n",
    "    \n",
    "- **Number to small**: \n",
    "    - small gradients for hidden layer inputs; \n",
    "    - gradient diminishing when flowing backwafrd\n",
    "    \n",
    "    \n",
    "- **Preferred: All neuron with a good output distribution**:\n",
    "    - Benefit: effective back-propagation for weights\n",
    "    - w = np.random.randn(n) / sqrt(n), where n is number of inputs. In other words, the standard error $std(w) = \\frac {1}{n}$\n",
    "    - It can be proved that Var(S) = Var(WX) = Var(X)\n",
    "    - It helps get a wide range of output value for each hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "x = np.random.randn(1000, 100) \n",
    "node_num = 100\n",
    "hidden_layer_size = 5\n",
    "activations = {}\n",
    "for i in range(hidden_layer_size):\n",
    "    if i != 0:\n",
    "        x = activations[i-1]\n",
    "    #w = np.random.randn(node_num, node_num) * 1\n",
    "    #w = np.random.randn(node_num, node_num) * 0.01\n",
    "    w = np.random.randn(node_num, node_num) / np.sqrt(node_num)\n",
    "    z = np.dot(x, w)\n",
    "    a = sigmoid(z)\n",
    "    activations[i] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAABUCAYAAACLH+AyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwAzs4ZyATAza6j/AfGcI7W+9LWmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2323fd31400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAABUCAYAAABpw/tLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYGZmOS4OZmaW838YW0kVkqF6FAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23240ef6518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAABUCAYAAABpw/tLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8txcTAzsxwXBzMzy3FxMDOznP8DsZZKa5xGKu4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2323fc66940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAABUCAYAAABpw/tLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni4OZmeW4OJiZWc7/ASIfJ6t7wKL7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2323fc8cc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAABUCAYAAABpw/tLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2323fdff550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, a in activations.items():\n",
    "    plt.subplot(len(activations),1 , i+1)\n",
    "    plt.title(str(i+1) + \"-layer\")\n",
    "    plt.hist(a.flatten(), 30, range=(0,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Batch Normalization**\n",
    "<img src=\"https://kratzert.github.io/images/bn_backpass/bn_algorithm.PNG\" width=\"400\">\n",
    "- **Force activation layer inputs to be $N(0,1)$**\n",
    "  \n",
    "- https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html\n",
    "\n",
    "- Improve gradient flow\n",
    "- Allow higher learning rates\n",
    "- **Reduce dependence on initialization**\n",
    "- Some regularization\n",
    "- *Note*: At test time, the mean from training should be used instead of calculated from testing batch\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/dlmmdcud1l06optimization-170427160940/95/optimizing-deep-networks-d1l6-insightdcu-machine-learning-workshop-2017-8-638.jpg?cb=1493309658\" width=500>\n",
    "- Fully connected layer\n",
    "    * X: (num_example, dimension)\n",
    "    * mu, sigma: 1 \\* D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- CNN -> Spatial Batchnorm\n",
    "    * X: (num_example, channels, height, width)\n",
    "    * mu, sigma: 1 \\* C \\* 1 \\* 1\n",
    "    \n",
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-36a6ee9c550f479fc681eab380510baf\" width=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Param Update and Learning Rate**\n",
    "- Step decay for learning rate: \n",
    "    * Reduce the learning rate by some factor every few epochs. \n",
    "    * Other approaches also avalable, like exponential decay, 1/t decay, etc.\n",
    "- Second-order update method:\n",
    "    * i.e., Newton's method, not common\n",
    "- Per-parameter adaptive learning rate methods: \n",
    "    * For example: Adagrad, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn3/nesterov.jpeg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Treat all elements of dX as a whole\n",
    "#  Intuition: \n",
    "#  If gradient direction not changed, increase update, faster convergence\n",
    "#  If gradient direction changed, reduce update, reduce oscillation\n",
    "\n",
    "def VanillaUpdate(x, dx, learning_rate):\n",
    "    x += -learning_rate * dx\n",
    "    return x\n",
    "\n",
    "def MomentumUpdate(x, dx, v, learning_rate, mu):\n",
    "    v = mu * v - learning_rate * dx # integrate velocity, mu's typical value is about 0.9\n",
    "    x += v # integrate position     \n",
    "    return x, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treat each element of dX adaptively\n",
    "# Intuition:\n",
    "# 1. Those dx receiving infrequent updates should have higher learning rate. vice versa \n",
    "# 2. We don't want: the gradients accumulate, and the learning rate monotically decrease, \n",
    "# 2. We want: modulates the learning rate of each weight based on the magnitudes of its gradient\n",
    "# 3. Still want to use \"momentum-like\" update to get a smooth gradient\n",
    "\n",
    "# 1. AdaGrad\n",
    "def AdaGrad(x, dx, learning_rate, cache, eps):\n",
    "    cache += dx**2\n",
    "    x += - learning_rate * dx / (np.sqrt(cache) + eps) # (usually set somewhere in range from 1e-4 to 1e-8)\n",
    "    return x, cache\n",
    "    \n",
    "# 1+2. RMSprop\n",
    "def RMSprop(x, dx, learning_rate, cache, eps, decay_rate): #Here, decay_rate typical values are [0.9, 0.99, 0.999]\n",
    "    cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "    x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "    return x, cache\n",
    "    \n",
    "# 1+2+3. Adam\n",
    "def Adam(x, dx, learning_rate, m, v, t, beta1, beta2, eps):\n",
    "    m = beta1*m + (1-beta1)*dx # Smooth gradient\n",
    "    #mt = m / (1-beta1**t) # bias-correction step\n",
    "    v = beta2*v + (1-beta2)*(dx**2) # keep track of past updates\n",
    "    #vt = v / (1-beta2**t) # bias-correction step\n",
    "    x += - learning_rate * m / (np.sqrt(v) + eps) # eps = 1e-8, beta1 = 0.9, beta2 = 0.999   \n",
    "    return x, m, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./fig/Optimizers.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **General Workflow**\n",
    "- Preprocess Data (zero-centered,i.e.,Sub-stractmean)\n",
    "- Identify architecture\n",
    "- Ensure that we can overfit a small traing set to acc = 100%\n",
    "- Loss not decreasing: too low leaning rate\n",
    "- Loss goes to NaN: too high learning rate  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Second Order Optimization**\n",
    "- No Hyperparameter and learning rates\n",
    "- N^2 elements, O(N^3) for taking inverting\n",
    "- Methods:\n",
    "    * Quasi-Newton methods(BGFS): O(N^3) -> O(N^2)\n",
    "    * L-BFGS: Does not form/store the full inverse Hessian.\n",
    "    \n",
    "## **Hardware**\n",
    "- CPU: less cores, faster per core, better at sequential tasks\n",
    "- GPU: more cores, slower per core, better at parallel tasks (NVIDIA, CUDA, cuDNN)\n",
    "- TPU: just for DL (Tensor Processing Unit)\n",
    "    * Split *One* graph over *Multiple* machines\n",
    "\n",
    "## **Software**\n",
    "- Caffe (FB)\n",
    "- PyTorch (FB)\n",
    "- TF (Google)\n",
    "- CNTK (MS)\n",
    "- Dynamic (e.g., Eager Execution) vs. Static (e.g., TF Lower-level API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "## Overview\n",
    "\n",
    "- Characteristics\n",
    "    - Spatial data like image, video, text, etc.\n",
    "    - Exploit the local structure of data\n",
    "\n",
    "\n",
    "- Application\n",
    "    - Object detection and localization; for example, pedestrian detection for AV, Facebook friends in photo, etc.\n",
    "    \n",
    "    - Image Segmentation; obtain boundary of each object in the image \n",
    "    \n",
    "**ConvNets**\n",
    "- Difference with regular NN:\n",
    "    * Main difference: each neuron is layer 2 is only connected to a few neurons in layer 1\n",
    "    * Data arranged in 3 dimensions: height, width, and depth\n",
    "- Convolutional Layer:\n",
    "    * Filter/Kernel (with full depth, but local connectivity across 2d), 3\\*3 --> 5\\*5\n",
    "    * The depth of layer 2 == The number of filters in Layer 1\n",
    "    * `Stride`: usually 1, leaving downsampling to pooling layer. Can use 2 to compromise 1st layer because of computational constraints\n",
    "    * `Padding`: use same to avoid missing information along the border\n",
    "    * *Parameter Sharing*: Same weight for filter/kernel at same depth slice in layer 2 (Alternative: local)\n",
    "- Pooling\n",
    "    * Most commonly: 2-2 Max Pooling\n",
    "- Fully-Connected Layer\n",
    "- Common architecture:\n",
    "    * INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]\\* -> [FC -> RELU]\\*2 -> FC\n",
    "    * Prefer a stack of small filter CONV to one large receptive field CONV layer\n",
    "- Challenge: Computational resources\n",
    "<img src=\"https://i.stack.imgur.com/AuqKy.png\" width=500>\n",
    "\n",
    "\n",
    "- Different features are detected at each layer. For example, AlexNet:\n",
    "    - More layers can be beneficial for learning complicated features\n",
    "<img src=\"https://banner2.kisspng.com/20180607/vcr/kisspng-deep-learning-convolutional-neural-network-alexnet-deep-learning-5b19637f4372c8.8890220615283905272763.jpg\" width=600>\n",
    "**Transfer Learning**\n",
    "- Apply trained model without last FC layer and use it as feature extracter\n",
    "- Continue to fine tune the model using smaller learning rate\n",
    "- Can use different image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "## Different architectures\n",
    "- LeNet-5 (CONV-Subsampling-CONV-Subsampling-FC-FC)\n",
    "    - Note: sigmoid activation and no Pooling/Dropout layer\n",
    "<img src=\"https://i.stack.imgur.com/tLKYz.png\" width=\"800\">\n",
    "\n",
    "- AlexNet 8 layers (CONV1-MAXPOOL1-NORM1-CONV2-MAXPOOL2-NORM2-CONV3-CONV4-CONV5-MAXPOOL3-FC6-FC7-FC8)\n",
    "    - Note: ReLU activation and Pooling/Dropout layer\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0106.png\" width=400>\n",
    "\n",
    "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_7/AlexNet_1.jpg\" width=\"300\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ZFNet (similar with AlexNet)\n",
    "    * Smaller kernel, more filters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VGGNet(*smaller* filter and *deeper* networks)\n",
    "    * 16-19 layers in VGG16Net\n",
    "    * Three 3 \\* 3 kernel with stride == One 7 \\* 7 kernel; Same *effective receptive field*\n",
    "    * ReLU activation function\n",
    "    * Optimizer: Adam\n",
    "    * Weight initialization: He\n",
    "   \n",
    "    * **deeper network and more non-linearity (more representation power);**\n",
    "    * **less parameters ( 3 \\* 3 \\* 3 vs. 7 \\* 7)**\n",
    "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_3/CascadingConvolutions.png\" width=500>\n",
    "<img src=\"http://josephpcohen.com/w/wp-content/uploads/Screen-Shot-2016-01-14-at-11.25.15-AM.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- GoogLeNet\n",
    "    * Introduced *inception* Module (Parallel filter operations with multiple kernel size)\n",
    "    * Problem: Output size too big after filter concatenation\n",
    "    * The purpose of 1 \\* 1 convolutonal layer: \n",
    "        - Pooling layer keeps the same depth as input\n",
    "        - 1 \\* 1 layer keeps the **same dimension** of input, and **reduces depth** (for example: 64 \\* 56 \\* 56 after 32 1 \\* 1 con --> 32 \\* 56 \\* 56)\n",
    "        - Reduce total number of operations\n",
    "    \n",
    "<img src=\"https://www.researchgate.net/profile/Bo_Zhao48/publication/312515254/figure/fig3/AS:489373281067012@1493687090916/nception-module-of-GoogLeNet-This-figure-is-from-the-original-paper-10.jpg\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- ResNet\n",
    "    * Use network layers to fit a *Residual mapping* instead of directly fitting a desired underlying mapping\n",
    "    * Residual blocks are stacked\n",
    "    * More effecvtive training by enabling gradients to be back-propagated without vanishing\n",
    "    * Similar to GoogLeNet, can use *bottelneck* layer (1 \\* 1 conv layer) for downsampling and efficiency ++\n",
    "    \n",
    "<img src=\"https://www.researchgate.net/profile/Antonio_Theophilo/publication/321347448/figure/fig2/AS:565869411815424@1511925189281/Bottleneck-Blocks-for-ResNet-50-left-identity-shortcut-right-projection-shortcut.png\" width=\"500\">\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/kBFIf.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Augmentation\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*dJNlEc7yf93K4pjRJL55PA.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "## Basic RNN\n",
    "<img src=\"http://www.wildml.com/wp-content/uploads/2015/09/rnn.jpg\" width=500>\n",
    "- What is the problem with RNN\n",
    "    * Gradient Vanishing/Exploding with Vanilla RNN\n",
    "    * Computing gradient of $ h_0 $ involved many multiplication of **W** and **tanh** activation (one small gradient would carry over)\n",
    "    * Brief proof:\n",
    "    \n",
    "    $ \\frac{ \\partial E_t} { \\partial w}= \\sum_{k=1}^{t}  \\frac{ \\partial E_t} { \\partial y_t}\\frac{ \\partial y_t} { \\partial h_t}\\frac{ \\partial h_t} { \\partial h_k}\\frac{ \\partial h_k} { \\partial w}$\n",
    "    Here:$ h_t = W_{hh} f(h_{t-1}) + W_{hx} X_t$              \n",
    "    $ \\frac{ \\partial h_t} { \\partial h_k}= \\prod_{j= k + 1}^{t} \\frac{ \\partial h_j} { \\partial h_{j-1}} $\n",
    "    \n",
    "    $ \\| \\frac{ \\partial h_t} { \\partial h_k} \\|\\leq (\\beta_W \\beta_h)^{t-k} $ $\\beta$ is upper bound for matrix norms\n",
    "    \n",
    "    $ \\| W^T_{hh} \\| \\leq \\beta_W $ and $ \\| diag(f'(h_{j-1}) \\| \\leq \\beta_h $\n",
    "    * We cannot figure out the dependency between long time interval's data\n",
    "\n",
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-d63725db196675d327f3e4578c48701b\" width=\"500\">\n",
    "\n",
    "- How to fix vanishing gradients?\n",
    "    * Partial fix for gradient exploding: if ||g|| > threshold, shrink value of g\n",
    "    * Initialize W to be identity\n",
    "    * Use ReLU as activation function f\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of RNN\n",
    "- Language modelling (see nlp repo for details)\n",
    "- seq2seq models for machine translations (see nlp repo for details)\n",
    "\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0706.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "- Main Idea of LSTM\n",
    "    * **Forget Gate** (\\*): how much old memory we want to keep; element-wise multiplication with old memory $ C_{t-1} $. The Parameters are learned as $ W_f $. I.e., $ \\sigma(W_f([h_{t-1}, X_t]) + b_f = f_t $. If you want all old memory, then $ f_t $ equals 1. After getting $ f_t $, multiply it with $ C_{t-1} $<br/><br/>\n",
    "   \n",
    "    * **New Memory Gate**(\\+)\n",
    "        - How to merge new memory with old memory; piece-wise summation, decides how to combine *new* memory with *old* memory. The weighing parameters are learned as $ W_i $. I.e., $ \\sigma(W_i([h_{t-1}, X_t]) + b_i = i_t $. \n",
    "    \n",
    "        - What is the new memory itself: $ tanh(W_C([h_{t-1}, X_t]) + b_C = \\tilde{C_t} $\n",
    "    \n",
    "        - What is the combined memory: $ C_{t-1} * f_t + \\tilde{C_t} * i_t = C_t$ <br/><br/>\n",
    "        \n",
    "    * **Output gate**: how much of the new memory we want to output or store? learned solely through combined memory. $ \\sigma(W_o([h_{t-1}, X_t]) + b_o = o_t $. Then the final output $ h_t $ would be $ o_t * tanh(C_t) = h_t $\n",
    "    \n",
    "    \n",
    "    \n",
    "- Why LSTM prevents gradient vanishing?\n",
    "    - *Linear* Connection between $C_t$ and $C_{t-1}$ rather than multiplying\n",
    "    - Forget gate controls and keeps long-distance dependency\n",
    "    - Allows error to flow at different strength based on inputs\n",
    "    - During initialization: Initialize forget gate bias to one: default to remembering\n",
    "    - See proof: https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html\n",
    "\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*LyfY3Mow9eCYlj7o.\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM\n",
    "<img src=\"https://guillaumegenthial.github.io/assets/char_representation.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other variation: Gated Recurrent Unit (GRU)\n",
    "- **Update Gate**: How to combine old and new state: $ \\sigma(W_z([h_{t-1}, X_t])  = z_t $\n",
    "- **Reset Gate**: How much to keep old state: $ \\sigma(W_r([h_{t-1}, X_t])= r_t $\n",
    "- **New State**: $ tanh(WX_t + r_t * U h_{t-1}) =\\tilde{h_t}$ \n",
    "- **Combine States**: $z_t* h_{t-1} + (1-z_t) * \\tilde{h_t} $\n",
    "- If r=0, ignore/drop previous state for generating new state\n",
    "- if z=1, carry information from past through many steps (long-term dependency)\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/ce3f6d276f10fef2c145daf0fe19c006c92ce019/687474703a2f2f636f6c61682e6769746875622e696f2f706f7374732f323031352d30382d556e6465727374616e64696e672d4c53544d732f696d672f4c53544d332d7661722d4752552e706e67\" width=600>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0705.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Captioning\n",
    "1. From image: [CONV-POOL] \\* n --> FC Layer --> (num_example, 4096) written as **v**\n",
    "2. Hiddern layer: $h = tanh(W_{xh} * X + W_{hh} * h + W_{ih} * \\bf{v} )$\n",
    "3. Output layer: $y = W_{hy} * h$\n",
    "4. Get input $ X_{t+1}$ by sampling $\\bf{y} $\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yunjey/pytorch-tutorial/master/tutorials/03-advanced/image_captioning/png/model.png\" width=\"500\">\n",
    "\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0108.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some general tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overfitting:\n",
    "    - Increase Dropout ratio\n",
    "    - Decrease layers\n",
    "    - Increase regularization\n",
    "    \n",
    "    \n",
    "- Underfitting:\n",
    "    - Increase layers\n",
    "    - Decrease regularization\n",
    "    - Decrease learning rate\n",
    "    \n",
    "\n",
    "- Gradient vanishing\n",
    "    - Batch Normalization\n",
    "    - Less layers\n",
    "    - Appropriate activation function\n",
    "    \n",
    "    \n",
    "- Local minima\n",
    "    - Increase learning rate\n",
    "    - Appropriate optimizer\n",
    "    - Smaller batch size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware\n",
    "- CPU\n",
    "- GPU (for parallel)\n",
    "- TPU (for matrix)\n",
    "\n",
    "## Parelleling\n",
    "\n",
    "\n",
    "- Data parallel training splits large datasets across multiple computing nodes\n",
    "    - Each worker node has a complete copy of the model being trained.\n",
    "    - One single as supervisor server.\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-for-deep/9781491980446/assets/tfdl_0908.png\" width=200>\n",
    "\n",
    "\n",
    "- Model parallel training splits large models across multiple nodes. \n",
    "    - Motivation: memory restriction on a single CPU\n",
    "    - Network itself is stored on multiple CPUs\n",
    "    - Not common..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {},
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "threshold": 4,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "632px",
    "left": "0px",
    "right": "1357.17px",
    "top": "106.992px",
    "width": "222px"
   },
   "toc_section_display": true,
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
