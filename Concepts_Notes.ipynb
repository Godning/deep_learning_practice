{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Workflow\n",
    "- Preprocess Data (zero-centered,i.e.,Substractmean)\n",
    "- Identify architecture\n",
    "- Ensure that we can overfit a small traing set to acc = 100%\n",
    "- Loss not decreasing: too low leaning rate\n",
    "- Loss goes to NaN: too high learning rate  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "- Improve gradient flow\n",
    "- Allow higher learning rates\n",
    "- Reduce dependence on initialization\n",
    "- Some regularization\n",
    "- *Note*: At test time, the mean from training should be used instead of calculated from testing batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "- Fully connected layer\n",
    "    * X: (num_example, dimension)\n",
    "    * mu, sigma: 1 \\* D\n",
    "\n",
    "\n",
    "- CNN -> Spatial Batchnorm\n",
    "    * X: (num_example, channels, height, width)\n",
    "    * mu, sigma: 1 \\* C \\* 1 \\* 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Normalization:\n",
    "- Fully connected layer\n",
    "    * X: (num_example, dimension)\n",
    "    * mu, sigma: N \\* 1 \n",
    "    * Note: same behavior during testing\n",
    "\n",
    "## Instance Normalization\n",
    "- CNN\n",
    "    * X: (num_example, channels, height, width)\n",
    "    * mu, sigma: N \\* C \\* 1 \\* 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Order Optimization\n",
    "- No Hyperparameter and learning rates\n",
    "- N^2 elements, O(N^3) for taking inverting\n",
    "- Methods:\n",
    "    * Quasi-Newton methods(BGFS): O(N^3) -> O(N^2)\n",
    "    * L-BFGS: Does not form/store the full inverse Hessian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware\n",
    "- CPU: less cores, faster per core, better at sequential tasks\n",
    "- GPU: more cores, slower per core, better at parallel tasks\n",
    "- TPU: just for DL (Tensor Processing Unit)\n",
    "    * Split *One* graph over *Multiple* machines\n",
    "\n",
    "## Software\n",
    "- Caffe (FB)\n",
    "- PyTorch (FB)\n",
    "- TF (Google)\n",
    "- CNTK (MS)\n",
    "- Dynamic (e.g., Eager Execution) vs. Static (e.g., TF Lower-level API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different CNN architectures\n",
    "\n",
    "- LeNet-5 (CONV-POOL-CONV-POOL-FC-FC)\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/tLKYz.png\" width=\"800\">\n",
    "\n",
    "- AlexNet 8 layers (CONV1-MAXPOOL1-NORM1-CONV2-MAXPOOL2-NORM2-CONV3-CONV4-CONV5-MAXPOOL3-FC6-FC7-FC8)\n",
    "\n",
    "<img src=\"https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/image_folder_7/AlexNet_1.jpg\" width=\"400\">\n",
    "\n",
    "- ZFNet (similar with AlexNet)\n",
    "    * Smaller kernel, more filters\n",
    "\n",
    "- VGGNet(*smaller* filter and *deeper* networks)\n",
    "    * 16-19 layers in VGG16Net\n",
    "    * Three 3 \\* 3 kernel with stride == One 7 \\* 7 kernel; Same *effective receptive field\n",
    "    * But: 1) deeper network and more non-linearity; 2) less parameters ( 3 \\* 3 \\* 3 vs. 7 \\* 7)\n",
    "<img src=\"http://josephpcohen.com/w/wp-content/uploads/Screen-Shot-2016-01-14-at-11.25.15-AM.png\" width=\"800\">\n",
    "\n",
    "- GoogLeNet\n",
    "    * Introduced *inception* Module (Parallel filter operations with multiple kernel size)\n",
    "    * Problem: Output size too big after filter concatenation\n",
    "    * The purpose of 1 \\* 1 convolutonal layer: \n",
    "        - Pooling layer keeps the same depth as input\n",
    "        - 1 \\* 1 layer keeps the same dimension of input, and reduces depth (for example: 64 \\* 56 \\* 56 after 32 1 \\* 1 con --> 32 \\* 56 \\* 56)\n",
    "        - Reduce total number of operations\n",
    "    \n",
    "<img src=\"https://www.researchgate.net/profile/Bo_Zhao48/publication/312515254/figure/fig3/AS:489373281067012@1493687090916/nception-module-of-GoogLeNet-This-figure-is-from-the-original-paper-10.jpg\" width=\"400\">\n",
    "\n",
    "- ResNet\n",
    "    * Use network layers to fit a *Residual mapping* instead of directly fitting a desired underlying mapping\n",
    "    * Residual blocks are stacked\n",
    "    * Similar to GoogLeNet, can use *bottelneck* layer (1 \\* 1 conv layer) for downsampling and efficiency ++\n",
    "    \n",
    "<img src=\"https://www.researchgate.net/profile/Antonio_Theophilo/publication/321347448/figure/fig2/AS:565869411815424@1511925189281/Bottleneck-Blocks-for-ResNet-50-left-identity-shortcut-right-projection-shortcut.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of RNN: Image Captioning\n",
    "1. From image: [CONV-POOL] \\* n --> FC Layer --> (num_example, 4096) written as **v**\n",
    "2. Hiddern layer: $ h = tanh(W_{xh} * X + W_{hh} * h + W_{ih} * \\bf{v} )$\n",
    "3. Output layer: $ y = W_{hy} * h\\ $\n",
    "4. Get input $ X_{t+1}\\ by\\ sampling\\ \\bf{y} $\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/yunjey/pytorch-tutorial/master/tutorials/03-advanced/image_captioning/png/model.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image captioning with Attention\n",
    "\n",
    "To be filled after LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "- Gradient Vanishing/Exploding with Vanilla RNN\n",
    "- Computing gradient of $ h_0 $ involved many multiplication of **W** and **tanh** activation\n",
    "\n",
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-d63725db196675d327f3e4578c48701b\" width=\"500\">\n",
    "\n",
    "- Main Idea of LSTM\n",
    "    * **Forget Gate** (\\*): how much old memory we want to keep; element-wise multiplication with old memory $ C_{t-1} $. The Parameters are learned as $ W_f $. I.e., $ \\sigma(W_f([h_{t-1}, X_t]) + b_f = f_t $. If you want all old memory, then $ f_t $ equals 1. After getting $ f_t $, multiply it with $ C_{t-1} $\n",
    "    \n",
    "    * **New Memory Gate**(\\+): \n",
    "        * How to merge new memory with old memory; piece-wise summation, decides how to combine *new* memory with *old* memory. The weighing parameters are learned as $ W_i $. I.e., $ \\sigma(W_i([h_{t-1}, X_t]) + b_i = i_t $. \n",
    "    \n",
    "        * What is the new memory itself: $ tanh(W_C([h_{t-1}, X_t]) + b_C = \\tilde{C_t} $\n",
    "    \n",
    "        * What is the combined memory: $ C_{t-1} * f_t + \\tilde{C_t} * i_t = o_t$\n",
    "    \n",
    "    * **Output gate**: how much of the new memory we want to output? learned solely through combined memory. $ \\sigma(W_o([h_{t-1}, X_t]) + b_o = o_t $. Then the final output $ h_t $ would be $ o_t * tanh(C_t) = h_t $\n",
    "    \n",
    "    \n",
    "- Why LSTM prevents gradient vanishing?\n",
    "    - Forget gate controls \n",
    "    - See proof: https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*laH0_xXEkFE0lKJu54gkFQ.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
